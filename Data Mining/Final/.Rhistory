setwd ("D:/DataScience_2019501071/Data Mining/Final")
if (Z_SGR_Close[k] > 3) {
outliers_count <- outliers_count + 1
outliers_dates[otd] <- bse_sensex$Date[k]
otd <- otd + 1
}
bse_sensex <- read.csv("BSE_Sensex_Index.csv")
SGR_Close <- c()
bse_sensex <- read.csv("BSE_Sensex_Index.csv")
SGR_Close <- c()
for (i in 1:15446){
SGR_Close[i] <- (bse_sensex$Close[i] - bse_sensex$Close[i+1]) / bse_sensex$Close[i+1]
}
SGR_Close[15447] <- (SGR_Close[15446] + SGR_Close[15445] + SGR_Close[15444]) / 3
SGR_Close[15447]
Z_SGR_Close <- c()
mean_SGR_Close <- mean(SGR_Close)
mean_SGR_Close
sd_SGR_Close <- sd(SGR_Close)
sd_SGR_Close
for (j in 1:15447) {
Z_SGR_Close[j] <- (SGR_Close[j] - mean_SGR_Close) / (sd_SGR_Close)
}
outliers_dates <- c()
outliers_count <- 0
otd <- 1
for (k in 1:15447) {
if (Z_SGR_Close[k] > 3) {
outliers_count <- outliers_count + 1
outliers_dates[otd] <- bse_sensex$Date[k]
otd <- otd + 1
}
if (Z_SGR_Close[k] < -3) {
outliers_count <- outliers_count + 1
outliers_dates[otd] <- bse_sensex$Date[k]
otd <- otd + 1
}
}
outliers_count
outliers_dates
getwd()
setwd("D:\DataScience_2019501071\Data Mining\Final")
ap = read.csv("apriori_data.csv", header = TRUE);
ap$TID <- NULL
library(arules)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
rules <- apriori(transactions, parameter = list(sup = 0.03, conf = 0.5,target="rules"))
inspect(sort(basket_rules, by = 'lift')[1:15])
itemFrequencyPlot(transactions, topN = 5)
setwd("D:\DataScience_2019501071\Data Mining\Final")
data = read.csv("apriori_data.csv", header = TRUE);
View(data)
data$TID <- NULL
library(arules)
write.csv(data,"itemslist.csv",quote = FALSE.row.names=TRUE)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
inspect(transactions)
frequent_itemsets <- apriori(transactions, parameter = list(sup = 0.03, conf = 0.5,target="frequent_itemsets"))
inspect(sort(frequent_itemsets)[1:15])
itemFrequencyPlot(transactions, topN = 5)
data = read.csv("apriori_data.csv", header = TRUE);
View(data)
data$TID <- NULL
library(arules)
write.csv(data, "ItemList.csv", quote = FALSE, row.names = TRUE)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
inspect(transactions)
frequent_itemsets <- apriori(transactions, parameter = list(sup = 0.03, conf = 0.5,target="frequent itemsets"))
data = read.csv("apriori_data.csv", header = TRUE);
View(data)
data$TID <- NULL
library(arules)
write.csv(data, "ItemList.csv", quote = FALSE, row.names = TRUE)
transactions = read.transactions("ItemList.csv", sep=',', rm.duplicates = TRUE)
inspect(transactions)
frequent_itemsets <- apriori(transactions, parameter = list(sup = 0.03, conf = 0.5,target="frequent itemsets"))
install.packages("caret")
